{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensors\n",
    "\n",
    "Tensors are a way of representing data. A tensor is an n-dimensional array, that can be used to represent images, audio, video, embeddings or any other kind of data. For example, we might represent an image with no colors as a 2D tensor (height, width), where each value inside the tensor represents the pixel intensity at that position. We can represent images with colors (RGB) as 3D tensors (channels, height, width), where we can \"stack\" 3 tensors representing 3 channels of that image.\n",
    "\n",
    "Tensors are the fundamental data structure in PyTorch. In this notebook, we will cover the basics of tensors, including what they are, how to create them and how to visualize them. For tensor operations, please refer to the `tensor_operations.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.3.0+cu121 in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: numpy==1.25.2 in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
      "Requirement already satisfied: pillow==9.4.0 in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (1.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0+cu121) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0+cu121) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0+cu121) (1.3.0)\n",
      "Torch version: 2.3.0+cu121\n",
      "Numpy version: 1.25.2\n",
      "PIL version: 9.4.0\n",
      "GPU enabled: True\n"
     ]
    }
   ],
   "source": [
    "# Ensures versions are correct\n",
    "! pip install torch==2.3.0 numpy==1.25.2 pillow==9.4.0 torchvision==0.18\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"PIL version: {PIL.__version__}\")\n",
    "print(f\"GPU enabled: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors\n",
    "\n",
    "There are lots of ways you can create tensors in PyTorch. Below you can see some examples of creating tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From random numbers or predefined distributions\n",
    "\n",
    "These can be useful when testing your code, giving examples or for doing tensor operations later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 2d tensor with all zeros\n",
    "x = torch.zeros(5, 3)\n",
    "\n",
    "# use .shape to get the shape of a tensor\n",
    "print(x.shape)\n",
    "\n",
    "# Print a tensor to visualize it. For smaller tensors, this is ok\n",
    "# but for larger ones, you may want to print them out as images or other data type\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2d tensor with all ones\n",
    "x = torch.ones(5, 3)\n",
    "\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2d tensor with all random integers, from 1 to 50, and shape (5, 3)\n",
    "x = torch.randint(low=1, high=50, size=(5,3))\n",
    "\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2d tensor with all random floats, ranging from 0 to 1, and shape (5, 3)\n",
    "x = torch.rand(5, 3)\n",
    "\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a normalized and standarized 2d tensor, using a normal distribution\n",
    "x = torch.normal(mean=0, std=1, size=(5, 3))\n",
    "\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "# use torch.mean(tensor) and torch.std(tensor) to get the mean and standard deviation of a tensor\n",
    "print(\"Mean: \", torch.mean(x))\n",
    "print(\"Standard Deviation:\", torch.std(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above block a few times. You should notice that the mean and the standard deviation are really variable. This is because of the number of samples inside the tensor. To get more consistent values, we can create a tensor with a bigger shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized and standarized tensor, with shape of a RGB converted mnist image\n",
    "x = torch.normal(mean=0, std=1, size=(3, 28, 28))\n",
    "\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "print(\"Mean: \", torch.mean(x))\n",
    "print(\"Standard Deviation:\", torch.std(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above block a few times. This time, the mean and the standard deviation should be closer to 0 and 1, respectively.\n",
    "\n",
    "Another thing you can notice is how difficult it is to visualize higher dimensional tensors using print statements like we have been doing. Later on, we will show you how to use matplotlib to visualize tensors as images instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From specified values or other data types\n",
    "\n",
    "This can be useful when you want to initialize a tensor with some specific values, or when you already loaded some data using other python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Downloads sample asset\n",
    "! wget -O astronaut.jpg https://raw.githubusercontent.com/pytorch/vision/main/gallery/assets/astronaut.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From simple python lists\n",
    "\n",
    "This is an easy and convenient way to create tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1d tensor from a simple list\n",
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2d tensor (2, 3) from a simple list\n",
    "x = torch.tensor([[1, 2, 3], \n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From numpy arrays\n",
    "\n",
    "Numpy arrays are an efficient way of representing n-dimensional matrices in python, and used by a broad number of libraries in Python. For example, opencv-python uses [BGR](https://stackoverflow.com/questions/367449/what-exactly-is-bgr-color-space) **(not RGB)** numpy arrays to represent images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array from a simple list\n",
    "array = np.array([1, 2, 3])\n",
    "\n",
    "print(type(array))\n",
    "print(array.shape)\n",
    "print(array)\n",
    "print()\n",
    "\n",
    "# Create a tensor from numpy array\n",
    "x = torch.from_numpy(array)\n",
    "\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a higher dimensional numpy array from a simple list\n",
    "array = np.array([[1, 2, 3], \n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(type(array))\n",
    "print(array.shape)\n",
    "print(array)\n",
    "print()\n",
    "\n",
    "# Create a tensor from numpy array\n",
    "x = torch.from_numpy(array)\n",
    "\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, tensors can be created from numpy arrays. But what if we wanted to get a numpy array back from it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a higher dimensional numpy array from a simple list\n",
    "array = np.array([[1, 2, 3], \n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(type(array))\n",
    "print(array.shape)\n",
    "print(array)\n",
    "print()\n",
    "\n",
    "# Create a tensor from numpy array\n",
    "x = torch.from_numpy(array)\n",
    "\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "# convert back to numpy array\n",
    "x = x.numpy()\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important notice**: Further on, we will learn that tensors can be passed to different devices. This is awesome because we can use our GPU to make calculations way faster than on our CPU. But one thing to notice is that numpy arrays are saved in the CPU memory, meaning that if you have a tensor in your GPU and tries to convert it to a  numpy array it will fail. Keep that in mind when developing your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From PIL Images\n",
    "\n",
    "When dealing with deep learning for computer vision, you might want to load your data using Pillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image from disk\n",
    "img = Image.open(\"astronaut.jpg\")\n",
    "\n",
    "print(type(img))\n",
    "print(img.size)\n",
    "print(img)\n",
    "print()\n",
    "\n",
    "# convert to a numpy array\n",
    "x = np.array(img)\n",
    "x = torch.tensor(x)\n",
    "\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tensor shapes for images**: Images in pytorch are usually expected to be in the shape (channels, height, width) or (C, H, W). Notice that PIL uses the format (H, W, C). To solve this, we can use the `.permute()` method which will be covered on the next session briefly. For more information about data convention for images in pytorch, please refer to [here](https://pytorch.org/vision/stable/transforms.html#supported-input-types-and-conventions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Tensors\n",
    "\n",
    "As we saw previously, we can use print statements to visualize simpler arrays. But for more complex arrays, like images with 3 channels, it would be much more convenient to visualize the tensor as an image. For this, we can use matplotlib or other libraries to visualize the tensor as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "! wget -O astronaut.jpg https://raw.githubusercontent.com/pytorch/vision/main/gallery/assets/astronaut.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image from disk\n",
    "img = Image.open(\"astronaut.jpg\")\n",
    "\n",
    "# convert to numpy array\n",
    "img = np.array(img)\n",
    "# convert to a tensor\n",
    "tensor = torch.tensor(img)\n",
    "\n",
    "# tensor in shape (512, 512, 3)\n",
    "print(tensor.shape)\n",
    "print()\n",
    "\n",
    "# since we are using pytorch, let's use the torchvision convention\n",
    "tensor = tensor.permute(2,0,1) # (H, W, C) -> (C, H, W)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a function to load an image and convert it to a tensor in the torchvision convention\n",
    "def load_image(path):\n",
    "    img = Image.open(path)\n",
    "    img = np.array(img)\n",
    "    # convert to a tensor\n",
    "    tensor = torch.tensor(img)\n",
    "    tensor = tensor.permute(2,0,1) # (H, W, C) -> (C, H, W)\n",
    "    return tensor\n",
    "\n",
    "x = load_image(\"astronaut.jpg\")\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "x = load_image(\"astronaut.jpg\")\n",
    "\n",
    "# try to visualize it\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we forgot about converting the tensor back to shape (H, W, C), let's do it and try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "x = load_image(\"astronaut.jpg\")\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print()\n",
    "\n",
    "x = x.permute(1, 2, 0) # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# try to visualize it\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! It accepted a tensor of shape (H, W, C) and displayed it. But, one **important note** is that this might not always. If the tensor is not on the CPU, we might actually get an error. Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "x = load_image(\"astronaut.jpg\")\n",
    "# move image to gpu (first cuda device)\n",
    "x = x.to(\"cuda:0\")\n",
    "# You might also use the .cuda() method as a shortcut to the above, like\n",
    "# x = x.cuda()\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print()\n",
    "\n",
    "x = x.permute(1, 2, 0) # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# try to visualize it\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid this kind of situation, one of the best practices is to ensure that the tensor you want to view is on CPU before, and in the numpy format. This should work with both tensors on the GPU and tensors already on the CPU, as we will see in the next two blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image in CPU\n",
    "x = load_image(\"astronaut.jpg\")\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print()\n",
    "\n",
    "x = x.permute(1, 2, 0) # (C, H, W) -> (H, W, C)\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print()\n",
    "\n",
    "# move to the cpu and return as numpy array\n",
    "array = x.to(\"cpu\").numpy()\n",
    "# you can also use the .cpu() method instead, like:\n",
    "# array = x.cpu().numpy()\n",
    "print(type(array))\n",
    "print(array.shape)\n",
    "\n",
    "plt.imshow(array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "x = load_image(\"astronaut.jpg\")\n",
    "# move to GPU\n",
    "x = x.to(\"cuda:0\")\n",
    "\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print()\n",
    "\n",
    "x = x.permute(1, 2, 0) # (C, H, W) -> (H, W, C)\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print()\n",
    "\n",
    "# move to the cpu and return as numpy array\n",
    "array = x.to(\"cpu\").numpy()\n",
    "# you can also use the .cpu() method instead, like:\n",
    "# array = x.cpu().numpy()\n",
    "\n",
    "print(type(array))\n",
    "print(array.shape)\n",
    "\n",
    "plt.imshow(array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a function so we can easily visualize tensors as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor(x):\n",
    "    \"\"\"\n",
    "    Takes a (C, H, W) tensor and displays it as an image.\n",
    "    \"\"\"\n",
    "    x = x.permute(1, 2, 0) # (C, H, W) -> (H, W, C)\n",
    "    # move to the cpu and return as numpy array\n",
    "    array = x.to(\"cpu\").numpy()\n",
    "    # you can also use the .cpu() method instead, like:\n",
    "    # array = x.cpu().numpy()\n",
    "    \n",
    "    plt.imshow(array)\n",
    "    plt.show()\n",
    "\n",
    "# load tensor in (C, H, W) shape in the cpu\n",
    "tensor = load_image(\"astronaut.jpg\")\n",
    "# shows the device the tensor is in\n",
    "print(type(tensor))\n",
    "print(tensor.shape)\n",
    "print(tensor.device)\n",
    "print()\n",
    "\n",
    "# move to GPU\n",
    "tensor = tensor.to(\"cuda:0\")\n",
    "print(type(tensor))\n",
    "print(tensor.shape)\n",
    "print(tensor.device)\n",
    "\n",
    "show_tensor(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Mutability\n",
    "\n",
    "TODO\n",
    "\n",
    "> Tip: \"Methods which mutate a tensor are marked with an underscore suffix. For example, torch.FloatTensor.abs_() computes the absolute value in-place and returns the modified tensor, while torch.FloatTensor.abs() computes the result in a new tensor.\" - from [tensor initialization and basic operations notes](https://pytorch.org/docs/stable/tensors.html#initializing-and-basic-operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor with some initial values\n",
    "t = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(t)  # Output: tensor([1, 2, 3])\n",
    "\n",
    "# Now, let's modify the second element of the tensor\n",
    "t[1] = 4\n",
    "\n",
    "print(t)  # Output: tensor([1, 4, 3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "\n",
    "Create a tensor with shape (3, 4) using a python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    "Create a tensor from a a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "\n",
    "Create a tensor that ranges (-1, 1) with shape (3, 28, 28). Display the mean and the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4:\n",
    "\n",
    "Load the `reward.jpg` image from disk and convert it to a tensor using the torchvision convention for the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PIL, or if you want to learn something new, try to use opencv-python (cv2)\n",
    "import cv2\n",
    "\n",
    "! wget -O reward.jpg https://raw.githubusercontent.com/pytorch/vision/main/gallery/assets/dog1.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5:\n",
    "\n",
    "Now display the image from exercise 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6:\n",
    "\n",
    "Create a tensor and move it to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7:\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
